{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from multiprocessing import Pool\n",
    "from scipy import stats, signal\n",
    "import scipy.io as si\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import timeit\n",
    "import scipy\n",
    "import glob\n",
    "import math\n",
    "import json\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "class featureExtractionPipeline:\n",
    "\n",
    "    def __init__(self,data):\n",
    "        with open('config.json') as config:\n",
    "            config = json.load(config)\n",
    "        self.numberOfChannels = config['numberOfChannels']\n",
    "        self.samplingFrequency = config['samplingFrequency']\n",
    "        self.windowSize = config['windowSize']\n",
    "        self.dataPath = config['dataPath']\n",
    "        self.objectPath = config['objectPath']\n",
    "        self.data = data\n",
    "        self.windowData = None\n",
    "        self.numberOfWindows = None\n",
    "        self.extracted_features = None\n",
    "\n",
    "    def Split(self):\n",
    "        split_length = self.windowSize * self.samplingFrequency\n",
    "        channels = []\n",
    "        for channel in self.data:\n",
    "            split = np.array_split(channel,split_length)\n",
    "            channels.append(split)\n",
    "        # return data of format channels * windows * recordings\n",
    "        self.windowData = np.asarray(channels)\n",
    "        self.numberOfWindows = len(self.windowData[0])\n",
    "\n",
    "    # Returns the upper_right_triangle of the matrix returns\n",
    "    ## Used as a utility function by other function\n",
    "    def upperRightTriangle(self,matrix):\n",
    "        accum = []\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(i+1, matrix.shape[1]):\n",
    "                accum.append(matrix[i, j])\n",
    "        return (np.asarray(accum))\n",
    "\n",
    "\n",
    "    # Returns the Eigenvalues of a Correlation matrix\n",
    "    ## Used as a utility function by other function\n",
    "    def eigenValues(self,X):\n",
    "        w, v = np.linalg.eig(X)\n",
    "        w = np.absolute(w)\n",
    "        w.sort()\n",
    "        return (w)\n",
    "\n",
    "\n",
    "    # Returns the FFT at the last axis\n",
    "    ## Used as a utility function by other function\n",
    "    def FFT(self,X):\n",
    "        return (np.fft.rfft(X))\n",
    "\n",
    "\n",
    "    # Finds PFD for a channel\n",
    "    ## Input is a single channel it used as a utility function by other function\n",
    "    def pfd_for_ch(self,ch):\n",
    "        diff = np.diff(ch, n=1, axis=0)\n",
    "        asign = np.sign(diff)\n",
    "        sign_changes = ((np.roll(asign, 1) - asign) != 0).astype(int)\n",
    "        N_delta = np.count_nonzero(sign_changes)\n",
    "        n = len(ch)\n",
    "        log10n = np.log10(n)\n",
    "        return (log10n / (log10n + np.log10(n / (n + 0.4 * N_delta))))\n",
    "\n",
    "\n",
    "    # Return the Correlation between the channel\n",
    "    ## Input is windowed_channel\n",
    "    def Correlation(self):\n",
    "        file_correlation = []\n",
    "        file_eigenvalues = []\n",
    "        for i in range(0,self.numberOfWindows):\n",
    "            l = list(self.windowData[:,i])\n",
    "            correlation = np.corrcoef(l)\n",
    "            correlation[np.where(np.isnan(correlation))] = -2\n",
    "            file_correlation.append(self.upperRightTriangle(correlation))\n",
    "            file_eigenvalues.append(self.eigenValues(correlation))\n",
    "        return([np.array(file_correlation).flatten(),np.array(file_eigenvalues).flatten()])\n",
    "\n",
    "\n",
    "    # Return the Freq Correlation between the channel\n",
    "    ## Input is windowed_channel and freq range of different bins\n",
    "    def freqBinning(self,freq_ranges):\n",
    "        out_file = []\n",
    "        for i in range(0,self.numberOfWindows):\n",
    "            X = np.abs(self.FFT(list(self.windowData[:,i])))\n",
    "            num_channels = X.shape[0]\n",
    "            num_time_samples = (X.shape[-1] - 1) * 2 # revert FFT shape change\n",
    "            func = np.mean\n",
    "\n",
    "            def binned_freq(data, out):\n",
    "                prev = freq_ranges[0]\n",
    "                for i, cur in enumerate(freq_ranges[1:]):\n",
    "                    prev_index = int(np.floor((prev / self.samplingFrequency) * num_time_samples))\n",
    "                    cur_index = int(np.floor((cur / self.samplingFrequency) * num_time_samples))\n",
    "                    out[i] = func(data[prev_index:cur_index])\n",
    "                    prev = cur\n",
    "\n",
    "            out = np.empty((num_channels, len(freq_ranges) - 1,))\n",
    "            for ch in range(num_channels):\n",
    "                binned_freq(X[ch], out[ch])\n",
    "\n",
    "            result = out[0]\n",
    "            for i in range (1,len(out)):\n",
    "                result = np.concatenate([result, out[i]])\n",
    "\n",
    "            result[np.where(np.isnan(result))] = -2\n",
    "            out_file.append(result)\n",
    "        return(np.array(out_file).flatten())\n",
    "\n",
    "\n",
    "    # Return PIB Spectral Entropy\n",
    "    ## Input is windowed_channel\n",
    "    def PIBSpectralEntropy(self,freq_ranges):\n",
    "        #print('PIB Entropy',end = '')\n",
    "        out_file = []\n",
    "        for i in range(0,self.numberOfWindows):\n",
    "            data = np.abs(self.FFT(list(self.windowData[:,i])))\n",
    "            num_channels = data.shape[0]\n",
    "            num_time_samples = float((data.shape[-1] - 1) * 2) # revert FFT shape change\n",
    "            def norm(X):\n",
    "                for i in range (len(X)):\n",
    "                    for j in range (len(X[i])):\n",
    "                        X[i][j] /= X[i][j]+1e-12\n",
    "                return X\n",
    "            psd = data ** 2\n",
    "            psd = norm(psd)\n",
    "            def binned_psd(psd, out):\n",
    "                prev = freq_ranges[0]\n",
    "                for i, cur in enumerate(freq_ranges[1:]):\n",
    "                    prev_index = int(np.floor((prev / 399.6097561) * num_time_samples))\n",
    "                    cur_index = int(np.floor((cur / 399.6097561399) * num_time_samples))\n",
    "                    out[i] = np.sum(psd[prev_index:cur_index])\n",
    "                    prev = cur\n",
    "            out = np.empty((num_channels, len(freq_ranges) - 1,))\n",
    "            for ch in range(num_channels):\n",
    "                binned_psd(psd[ch], out[ch])\n",
    "            psd_per_bin = norm(out)\n",
    "            def entropy_per_channel(psd):\n",
    "                entropy_components = psd * np.log2(psd + 1e-12)\n",
    "                entropy = -np.sum(entropy_components) / np.log2(psd.shape[-1])\n",
    "                return entropy\n",
    "\n",
    "            out = np.empty((num_channels,))\n",
    "            for i, ch in enumerate(psd_per_bin):\n",
    "                out[i] = entropy_per_channel(ch)\n",
    "\n",
    "            out_file.append(out)\n",
    "        return(np.array(out_file).flatten())\n",
    "\n",
    "\n",
    "    def ShannonEntropy(self,freq_ranges,flatten = True):\n",
    "        #print('Extracting Shannons',end = '')\n",
    "        out_file = []\n",
    "        for i in range(0,self.numberOfWindows):\n",
    "            fft_mag = np.abs(self.FFT(list(self.windowData[:,i])))\n",
    "            num_time_samples = (fft_mag.shape[-1] - 1) * 2 # revert FFT shape change\n",
    "            X = fft_mag ** 2\n",
    "            for ch in X:\n",
    "                ch /= np.sum(ch + 1e-12)\n",
    "            psd = X\n",
    "            out = []\n",
    "            for start_freq, end_freq in zip(freq_ranges[:-1],  freq_ranges[1:]):\n",
    "                start_index = int(np.floor((start_freq / 399.6097561) * num_time_samples))\n",
    "                end_index = int(np.floor((end_freq / 399.6097561) * num_time_samples))\n",
    "                selected = psd[:, start_index:end_index]\n",
    "                entropies = - np.sum(selected * np.log2(selected + 1e-12), axis=selected.ndim-1) / np.log2(end_index - start_index)\n",
    "                if flatten:\n",
    "                    out.append(entropies.ravel())\n",
    "                else:\n",
    "                    out.append(entropies)\n",
    "            out_file.append(np.concatenate(out))\n",
    "        return(np.array(out_file).flatten())\n",
    "\n",
    "\n",
    "    # Returns Higuchi Fractal Dimention\n",
    "    ## Input is windowed_channel\n",
    "    def HFD(self,Kmax = 2):\n",
    "        #print('Extracting HFD',end = '')\n",
    "        out_file = []\n",
    "        for i in range(0,self.numberOfWindows):\n",
    "            epochs = self.windowData[:,i]\n",
    "            result = list()\n",
    "            for epoch in epochs:\n",
    "                N = len(epoch)\n",
    "                Lmk = np.zeros((Kmax,Kmax))\n",
    "                for k in range(1, Kmax+1):\n",
    "                    for m in range(1, k+1):\n",
    "                        Lmki = 0\n",
    "                        maxI = int((N-m)/k)\n",
    "                        for i in range(1,maxI+1):\n",
    "                            Lmki = Lmki + np.abs(epoch[m+i*k-1]-epoch[m+(i-1)*k-1])\n",
    "                        normFactor = (N-1)/(maxI*k)\n",
    "                        Lmk[m-1,k-1] = normFactor * Lmki\n",
    "                Lk = np.zeros((Kmax, 1))\n",
    "\n",
    "                for k in range(1, Kmax+1):\n",
    "                    Lk[k-1,0] = np.nansum(Lmk[range(k),k-1])/k/k\n",
    "\n",
    "                lnLk = np.log(Lk)\n",
    "                lnk = np.log(np.divide(1., range(1, Kmax+1)))\n",
    "                fit = np.polyfit(lnk,lnLk,1)\n",
    "                result.append(fit[0][0])\n",
    "\n",
    "            out_file.append(np.array(result))\n",
    "        return (np.array(out_file).flatten())\n",
    "\n",
    "\n",
    "    # Returns Petrosian fractal dimension\n",
    "    ## Input is windowed_channel\n",
    "    def PFD(self):\n",
    "        #print('Extracting PFD',end = '')\n",
    "        out_file = []\n",
    "        for i in range(0,self.numberOfWindows):\n",
    "            X = self.windowData[:,i]\n",
    "            out_file.append(np.asarray([self.pfd_for_ch(ch) for ch in X]))\n",
    "        return(np.array(out_file).flatten())\n",
    "\n",
    "\n",
    "    # Returns the hursts values\n",
    "    ## Input is windowed_channel\n",
    "    def Hurst(self):\n",
    "        #print('Extracting Hurst',end = '')\n",
    "        out_file = []\n",
    "        for i in range(0,self.numberOfWindows):\n",
    "            channels = self.windowData[:,i]\n",
    "            result = list()\n",
    "            for channel in channels:\n",
    "                x = np.array(channel)\n",
    "                x = x-x.mean()\n",
    "                z = np.cumsum(x)\n",
    "                r = np.array((np.maximum.accumulate(z) - np.minimum.accumulate(z))[1:])\n",
    "                s = pd.Series(x).expanding().std()[1:]\n",
    "                s[s == 0] = 1e-12\n",
    "                r += 1e-12\n",
    "                y_axis = np.log(r / s)\n",
    "                x_axis = np.log(np.arange(1, len(y_axis) + 1))\n",
    "                x_axis = np.vstack([x_axis, np.ones(len(x_axis))]).T\n",
    "                m, b = np.linalg.lstsq(x_axis, y_axis)[0]\n",
    "                result.append(m)\n",
    "                result.append(b)\n",
    "            out_file.append(result)\n",
    "        return (np.array(out_file).flatten())\n",
    "\n",
    "\n",
    "    # Returns Hjorth Fractal Dimention\n",
    "    ## Input is windowed_channel\n",
    "    def hjorthFD(self,kmax=3):\n",
    "        #print('Extracting Hjorth',end = '')\n",
    "        out_file = []\n",
    "        for ww in range(0,self.numberOfWindows):\n",
    "            channels = self.windowData[:,ww]\n",
    "            result = list()\n",
    "            for X in channels:\n",
    "                L = []\n",
    "                x = []\n",
    "                N = len(X)\n",
    "                for k in range(1,kmax):\n",
    "                    Lk = []\n",
    "                    for m in range(k):\n",
    "                        Lmk = 0\n",
    "                        for i in range(1,int(math.floor((N-m)/k))):\n",
    "                            Lmk += np.abs(X[m+i*k] - X[m+i*k-k])\n",
    "                        Lmk = Lmk*(N - 1)/math.floor((N - m) / k) / k\n",
    "                        Lk.append(Lmk)\n",
    "                    L.append(np.log(np.nanmean(Lk)))   # Using the mean value in this window to compare similarity to other windows\n",
    "                    x.append([np.log(float(1) / k), 1])\n",
    "\n",
    "                (p, r1, r2, s)= np.linalg.lstsq(x, L)  # Numpy least squares solution\n",
    "                result.append(p[0])\n",
    "            out_file.append(result)\n",
    "        return (np.array(out_file).flatten())\n",
    "\n",
    "\n",
    "    # Katz Fractal Dimention\n",
    "    ## Input is windowed_channel\n",
    "    def katzFD(self):\n",
    "        #print('Extracting katz',end = '')\n",
    "        out_file = []\n",
    "        for i in range(self.numberOfWindows):\n",
    "            channels = self.windowData[:,i]\n",
    "            result = list()\n",
    "            for data in channels:\n",
    "                n = len(data)-1\n",
    "                L = np.hypot(np.diff(data), 1).sum() # Sum of distances\n",
    "                d = np.hypot(data - data[0], np.arange(len(data))).max() # furthest distance from first point\n",
    "                a = np.log10(n) / (np.log10(d/L) + np.log10(n))\n",
    "                result.append(a)\n",
    "            out_file.append(result)\n",
    "        return(np.array(out_file).flatten())\n",
    "\n",
    "\n",
    "    # # Power Spectral Density\n",
    "    #  1. Largest amplitude value in PSD.\n",
    "    #  2. Frequency of the largest peak.\n",
    "    #  3. Second largest amplitude value in PSD.\n",
    "    #  4. Frequency of the second largest peak.\n",
    "    def psd(self):\n",
    "        #print('Extracting PSD',end = '')\n",
    "        out_file = []\n",
    "        for i in range(self.numberOfWindows):\n",
    "            channels = self.windowData[:,i]\n",
    "            result = list()\n",
    "            for channel in channels:\n",
    "                f, Pxx_den = signal.periodogram(list(channel))\n",
    "                f = f.tolist()\n",
    "                Pxx_den = Pxx_den.tolist()\n",
    "                max_one = max(Pxx_den)\n",
    "                freq_max_one = f[Pxx_den.index(max(Pxx_den))]\n",
    "                Pxx_den.pop(Pxx_den.index(max(Pxx_den)))\n",
    "                max_two = max(Pxx_den)\n",
    "                freq_max_two = f[Pxx_den.index(max(Pxx_den))]\n",
    "                result.append(max_one)\n",
    "                result.append(freq_max_one)\n",
    "                result.append(max_two)\n",
    "                result.append(freq_max_two)\n",
    "            out_file.append(result)\n",
    "        return (np.array(out_file).flatten())\n",
    "\n",
    "\n",
    "    # Skewness and Kurtosis\n",
    "    ## Input is windowed_channel\n",
    "    def moments(self):\n",
    "        #print('Extracting moments',end = '')\n",
    "        out_file = []\n",
    "        for i in tqdm(range(self.numberOfWindows)):\n",
    "            result = list()\n",
    "            channels = self.windowData[:,i]\n",
    "            for data in channels:\n",
    "                skewness = stats.skew(data, axis=0, bias=True)\n",
    "                kurtosis = stats.kurtosis(data, axis=0, fisher=True, bias=True, nan_policy='propagate')\n",
    "                result.append(skewness)\n",
    "                result.append(kurtosis)\n",
    "            out_file.append(result)\n",
    "        return (np.array(out_file).flatten())\n",
    "\n",
    "\n",
    "    def createTrainingData(self):\n",
    "        self.Split()\n",
    "        self.extracted_features = [\n",
    "        self.Correlation(),\n",
    "        self.freqBinning([0.5, 2.25, 4, 5.5, 7, 9.5, 12, 21, 30, 39, 48]),\n",
    "        self.PIBSpectralEntropy([0.25, 1, 1.75, 2.5, 3.25, 4, 5, 8.5, 12, 15.5, 19.5, 24]),\n",
    "        self.PIBSpectralEntropy([0.25, 2, 3.5, 6, 15, 24]),\n",
    "        self.PIBSpectralEntropy([0.25, 2, 3.5, 6, 15]),\n",
    "        self.PIBSpectralEntropy([0.25, 2, 3.5]),\n",
    "        self.PIBSpectralEntropy([6, 15, 24]),\n",
    "        self.PIBSpectralEntropy([2, 3.5, 6]),\n",
    "        self.PIBSpectralEntropy([3.5, 6, 15]),\n",
    "        self.ShannonEntropy([1,2,3]),\n",
    "        #self.HFD()\n",
    "        self.PFD(),\n",
    "        self.Hurst(),\n",
    "        #self.hjorthFD()\n",
    "        self.katzFD(),\n",
    "        #self.psd()\n",
    "        self.moments()]\n",
    "        self.extracted_features = np.array(self.extracted_features).flatten()\n",
    "        \n",
    "    def runPipeline(self):\n",
    "        self.createTrainingData()\n",
    "        return(self.extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1280/1280 [00:08<00:00, 159.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nl = pd.read_csv(files[1])\\nl = np.array(l)\\npipeline = featureExtractionPipeline(l)\\nprint(len(pipeline.runPipeline()))\\n\\nl = pd.read_csv(files[2])\\nl = np.array(l)\\npipeline = featureExtractionPipeline(l)\\nprint(len(pipeline.runPipeline()))\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('../../data/*.csv')\n",
    "l = pd.read_csv(files[0])\n",
    "l = np.array(l)\n",
    "pipeline = featureExtractionPipeline(l)\n",
    "l = pipeline.runPipeline()\n",
    "'''\n",
    "l = pd.read_csv(files[1])\n",
    "l = np.array(l)\n",
    "pipeline = featureExtractionPipeline(l)\n",
    "print(len(pipeline.runPipeline()))\n",
    "\n",
    "l = pd.read_csv(files[2])\n",
    "l = np.array(l)\n",
    "pipeline = featureExtractionPipeline(l)\n",
    "print(len(pipeline.runPipeline()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 14 is out of bounds for axis 0 with size 14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-c3bfdf358ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 14 is out of bounds for axis 0 with size 14"
     ]
    }
   ],
   "source": [
    "l[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
