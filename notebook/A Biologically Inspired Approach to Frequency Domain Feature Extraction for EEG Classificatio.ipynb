{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.metrics import sensitivity_specificity_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from scipy.integrate import simps\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import glob\n",
    "import mne\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeMeanFromChannels(channel_data):\n",
    "    channel_data = channel_data.transpose()\n",
    "    scaled_data = StandardScaler(with_std = False).fit_transform(channel_data)\n",
    "    return scaled_data.transpose()\n",
    "    \n",
    "def getMneRaw(data_to_process):\n",
    "    sfreq = 128\n",
    "    channel_names = ['F3', 'Fz', 'F4', 'C3', 'Cz', 'C4', 'P3',\n",
    "                     'P4', 'FC5', 'FC1', 'FC2', 'FC4', 'CP5',\n",
    "                     'CP1', 'CP2', 'CP4']\n",
    "    channel_type = {k:'eeg' for k in channel_names}\n",
    "    info = mne.create_info(channel_names, sfreq,verbose=False)\n",
    "    raw = mne.io.RawArray(removeMeanFromChannels(data_to_process), info, verbose=False)\n",
    "    raw.set_channel_types(channel_type)\n",
    "    montage = mne.channels.read_montage('standard_1020')\n",
    "    raw.set_montage(montage,verbose=False)\n",
    "    raw.filter(0,50,fir_design='firwin',verbose=False)\n",
    "    return raw\n",
    "\n",
    "def getFileInfo(file_path):\n",
    "    try:\n",
    "        raw_data = pd.read_csv(file_path,header=None)\n",
    "        data_to_process = raw_data[:-1]\n",
    "        label = int( list(set(raw_data.iloc[len(raw_data) -1 ].values))[0] )\n",
    "        raw = getMneRaw(data_to_process)\n",
    "        return [ raw, label ]\n",
    "    except:\n",
    "        return [0, 0]\n",
    "    \n",
    "def getPSDFeatures(data):\n",
    "    sf = 128\n",
    "    window = 2*sf\n",
    "    overlap = window//2\n",
    "    freqs, psd = signal.welch(data, sf, nperseg=window, noverlap = overlap)\n",
    "    alpha_indexes = np.where((freqs >= 8)&(freqs < 13))\n",
    "    alpha_values = psd[alpha_indexes]\n",
    "    alpha_values.sort()\n",
    "\n",
    "    beta_indexes = np.where((freqs >= 13)&(freqs < 30))\n",
    "    beta_values = psd[beta_indexes]\n",
    "    beta_values.sort()\n",
    "    features = [alpha_values[-1],beta_values[-1],beta_values[-2]]\n",
    "    return features\n",
    "\n",
    "\n",
    "def bandpower(eeg,sf=128,window_sec=None, relative=False):\n",
    "    band_power = {}\n",
    "    for channel_name,data in list(zip(eeg.info['ch_names'], eeg.get_data())):\n",
    "        band_dic = {}\n",
    "        for band_name in bands:\n",
    "            band = np.asarray(bands[band_name])\n",
    "            low, high = band\n",
    "            if window_sec is not None:\n",
    "                nperseg = window_sec * sf\n",
    "            else:\n",
    "                nperseg = (2 / low) * sf\n",
    "            freqs, psd = signal.welch(data, sf, nperseg=nperseg)\n",
    "            freq_res = freqs[1] - freqs[0]\n",
    "            idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "            bp = simps(psd[idx_band], dx=freq_res)\n",
    "            if relative:\n",
    "                bp /= simps(psd, dx=freq_res)\n",
    "            band_dic[band_name]= bp\n",
    "        band_power[channel_name] = band_dic\n",
    "    return band_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../data/open_bci/2colourswifi_transition/*.csv')\n",
    "bands = {\n",
    "    'alpha':[8,13],'beta':[13,30],'gamma':[30,200],\n",
    "'delta':[1,4],'theta':[4,8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b568a89d650458f857daf653cad40d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=288), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data_list = []\n",
    "training_label_list = []\n",
    "\n",
    "for i in tqdm(files):\n",
    "    raw_data_label = getFileInfo(i)\n",
    "    file_features = []\n",
    "    if raw_data_label[0] != 0:\n",
    "        band_feature = bandpower(raw_data_label[0])\n",
    "        for channel in band_feature:\n",
    "            file_features.append(list(band_feature[channel].values()))\n",
    "        training_data_list.append(sum(file_features, []))\n",
    "        training_label_list.append(raw_data_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(training_data_list)\n",
    "Y = training_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5116279069767442"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "classifier.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_metrics = pd.DataFrame(classification_report(y_test, y_pred, output_dict = True))\n",
    "basic_metrics = basic_metrics[basic_metrics.columns[:2]]\n",
    "basic_metrics.columns = [1,2]\n",
    "other_metrics = pd.DataFrame(sensitivity_specificity_support(y_test, y_pred), columns=[1,2])\n",
    "other_metrics.index = ['sensitivity','specificity','support']\n",
    "metric = pd.concat([basic_metrics,other_metrics]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1          2\n",
       "precision     0.500000   0.520000\n",
       "recall        0.428571   0.590909\n",
       "f1-score      0.461538   0.553191\n",
       "support      42.000000  44.000000\n",
       "specificity   0.590909   0.428571"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
