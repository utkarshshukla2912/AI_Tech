{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from features import featureExtractionPipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import moment\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyeeg\n",
    "import glob\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array = []\n",
    "files = glob.glob('../data/2colours_muse_transition/*.csv')\n",
    "files += glob.glob('../data/2colours_muse_onlycolor/*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PER FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cb6a2669b7407c8e9c908150733346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=464), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_array = []\n",
    "label_array = []\n",
    "for file in tqdm(files):\n",
    "    per_file_features = []\n",
    "    data = pd.read_csv(file,header=None)\n",
    "    channels = data[:-1]\n",
    "    label = data.iloc[-1]\n",
    "    label = int(list(set(label))[0])\n",
    "    for i in range(len(channels)):\n",
    "        channel = channels.iloc[i].values\n",
    "        channel_features = featureExtractionPipeline(channel,fs=256).runPipeline()\n",
    "        per_file_features.append(channel_features)\n",
    "    label_array.append(label)\n",
    "    feature_array.append(per_file_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(feature_array,label_array)\n",
    "\n",
    "y_train = OneHotEncoder(sparse=True).fit_transform(np.array(y_train).reshape(len(y_train),1))\n",
    "y_test = OneHotEncoder(sparse=True).fit_transform(np.array(y_test).reshape(len(y_test),1))\n",
    "\n",
    "X_train_flat = np.array(X_train).flatten()\n",
    "X_train_flat = X_train_flat.reshape(len(X_train_flat),1)\n",
    "X_test_flat = np.array(X_test).flatten()\n",
    "X_test_flat = X_test_flat.reshape(len(X_test_flat),1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_flat_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_train_scaled = X_train_flat_scaled.flatten().reshape(np.array(X_train).shape)\n",
    "X_train_scaled = X_train_scaled.reshape(len(X_train_scaled),4,29,1)\n",
    "\n",
    "X_test_flat_scaled = scaler.fit_transform(X_test_flat)\n",
    "X_test_scaled = X_test_flat.flatten().reshape(np.array(X_test).shape)\n",
    "X_test_scaled = X_test_scaled.reshape(len(X_test_scaled),4,29,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == 2:\n",
    "        y_train[i] = 0\n",
    "        \n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == 2:\n",
    "        y_test[i] = 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "#create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=2, activation='relu', input_shape=(4,29,1)))\n",
    "model.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled,y_train,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
